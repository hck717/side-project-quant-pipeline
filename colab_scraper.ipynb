{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hck717/side-project-quant-pipeline/blob/main/colab_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2LXs138Zc_V",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# --- PARAMETERS CELL ---\n",
        "# Tag this cell with \"parameters\" in Jupyter/Colab metadata\n",
        "KAFKA_BROKER = \"\"  # Papermill will override this\n",
        "\n",
        "\n",
        "# --- CONFIG ---\n",
        "crypto_tickers = [\"BTC-USD\", \"ETH-USD\", \"SOL-USD\", \"ADA-USD\", \"XRP-USD\"]\n",
        "equity_tickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"NVDA\", \"JPM\", \"XOM\", \"META\", \"GOOGL\", \"NFLX\"]\n",
        "treasury_tickers = [\"^TNX\", \"^IRX\", \"^FVX\", \"^TYX\"]\n",
        "\n",
        "crypto_topic = \"crypto_ticks\"\n",
        "equity_topic = \"equities_ticks\"\n",
        "bonds_topic = \"bonds_data\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeKfa6zEK7bs"
      },
      "outputs": [],
      "source": [
        "# --- INSTALL DEPENDENCIES ---\n",
        "!pip install --quiet yfinance confluent-kafka pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD48nc9LK8on"
      },
      "outputs": [],
      "source": [
        "# --- IMPORTS ---\n",
        "import yfinance as yf\n",
        "import json\n",
        "from confluent_kafka import Producer\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMGXBmu1K97u"
      },
      "outputs": [],
      "source": [
        "# --- BROKER SETUP ---\n",
        "if not KAFKA_BROKER:\n",
        "    KAFKA_BROKER = \"localhost:9092\"\n",
        "\n",
        "print(f\"üì° Connecting to Kafka broker: {KAFKA_BROKER}\")\n",
        "producer = Producer({'bootstrap.servers': KAFKA_BROKER})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8usZI4IK_JB"
      },
      "outputs": [],
      "source": [
        "# --- PRODUCE FUNCTION ---\n",
        "def produce_latest(symbols, topic, interval=\"1m\"):\n",
        "    print(f\"\\n=== Fetching {topic} ===\")\n",
        "    df = yf.download(symbols, period=\"1d\", interval=interval, group_by='ticker', threads=True)\n",
        "\n",
        "    for sym in symbols:\n",
        "        try:\n",
        "            sym_df = df[sym].reset_index()\n",
        "        except (KeyError, AttributeError):\n",
        "            sym_df = df.reset_index()\n",
        "\n",
        "        sym_df = sym_df.dropna(subset=[\"Datetime\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
        "        if sym_df.empty:\n",
        "            print(f\"‚ö†Ô∏è No valid data for {sym}\")\n",
        "            continue\n",
        "\n",
        "        latest_ts = sym_df[\"Datetime\"].max()\n",
        "        latest_rows = sym_df[sym_df[\"Datetime\"] == latest_ts]\n",
        "\n",
        "        for _, row in latest_rows.iterrows():\n",
        "            msg = {\n",
        "                \"symbol\": sym,\n",
        "                \"timestamp\": row[\"Datetime\"].isoformat(),\n",
        "                \"open\": float(row[\"Open\"]),\n",
        "                \"high\": float(row[\"High\"]),\n",
        "                \"low\": float(row[\"Low\"]),\n",
        "                \"close\": float(row[\"Close\"]),\n",
        "                \"volume\": float(row[\"Volume\"]),\n",
        "                \"ingested_at\": datetime.now(timezone.utc).isoformat()\n",
        "            }\n",
        "            print(f\"[SCRAPE DEBUG] {topic} {msg}\")\n",
        "            try:\n",
        "                producer.produce(topic, json.dumps(msg).encode('utf-8'))\n",
        "            except BufferError as e:\n",
        "                print(f\"‚ùå Failed to produce message for {sym}: {e}\")\n",
        "\n",
        "    producer.flush()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-RFNEnQLBw5"
      },
      "outputs": [],
      "source": [
        "# --- RUN SCRAPES ---\n",
        "produce_latest(crypto_tickers, crypto_topic, interval=\"1m\")\n",
        "produce_latest(equity_tickers, equity_topic, interval=\"1m\")\n",
        "produce_latest(treasury_tickers, bonds_topic, interval=\"1d\")\n",
        "\n",
        "print(\"\\n‚úÖ All data produced to Kafka topics.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3-RFNEnQLBw5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOYWhllEsQWx0x4t0dUSNjn",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
